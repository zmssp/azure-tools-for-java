<!--
  ~ Copyright (c) Microsoft Corporation
  ~
  ~ All rights reserved.
  ~
  ~ MIT License
  ~
  ~ Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
  ~ documentation files (the "Software"), to deal in the Software without restriction, including without limitation
  ~ the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
  ~ to permit persons to whom the Software is furnished to do so, subject to the following conditions:
  ~
  ~ The above copyright notice and this permission notice shall be included in all copies or substantial portions of
  ~ the Software.
  ~
  ~ THE SOFTWARE IS PROVIDED *AS IS*, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
  ~ THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
  ~ AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
  ~ TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
  ~ SOFTWARE.
  -->

<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
    <parent>
        <relativePath>../pom.xml</relativePath>
        <groupId>com.microsoft.azuretools</groupId>
        <artifactId>spark-tools</artifactId>
        <version>0.1.1</version>
    </parent>

    <modelVersion>4.0.0</modelVersion>
    <artifactId>spark-tools</artifactId>
    <version>0.1.1_2.3</version>
    <name>${project.artifactId}-${project.version}</name>
    <properties>
        <spark.version>2.3.0</spark.version>
        <hadoop.version>2.6.5</hadoop.version>
    </properties>

    <build>
        <plugins>
            <!-- Scalatest runs all Scala tests -->
            <plugin>
                <groupId>org.scalatest</groupId>
                <artifactId>scalatest-maven-plugin</artifactId>
                <version>1.0</version>
                <!-- Note config is repeated in surefire config -->
                <configuration>
                    <reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>
                    <junitxml>.</junitxml>
                    <filereports>SparkTestSuite.txt</filereports>
                    <argLine>-ea -Xmx3g -Xss4m -XX:ReservedCodeCacheSize=${CodeCacheSize}</argLine>
                    <stderr/>
                    <environmentVariables>
                        <!--
                          Setting SPARK_DIST_CLASSPATH is a simple way to make sure any child processes
                          launched by the tests have access to the correct test-time classpath.
                        -->
                        <SPARK_DIST_CLASSPATH>${test_classpath}</SPARK_DIST_CLASSPATH>
                        <SPARK_PREPEND_CLASSES>1</SPARK_PREPEND_CLASSES>
                        <SPARK_SCALA_VERSION>${scala.version.major}</SPARK_SCALA_VERSION>
                        <SPARK_TESTING>1</SPARK_TESTING>
                        <JAVA_HOME>${java.home}</JAVA_HOME>
                    </environmentVariables>
                    <systemProperties>
                        <log4j.configuration>file:src/test/resources/log4j.properties</log4j.configuration>
                        <derby.system.durability>test</derby.system.durability>
                        <java.awt.headless>true</java.awt.headless>
                        <java.io.tmpdir>${project.build.directory}/tmp</java.io.tmpdir>
                        <spark.test.home></spark.test.home>
                        <spark.testing>1</spark.testing>
                        <spark.ui.enabled>false</spark.ui.enabled>
                        <spark.ui.showConsoleProgress>false</spark.ui.showConsoleProgress>
                        <spark.unsafe.exceptionOnMemoryLeak>true</spark.unsafe.exceptionOnMemoryLeak>
                        <!-- Needed by sql/hive tests. -->
                        <test.src.tables>__not_used__</test.src.tables>
                    </systemProperties>
                    <tagsToExclude>${test.exclude.tags}</tagsToExclude>
                </configuration>
                <executions>
                    <execution>
                        <id>test</id>
                        <goals>
                            <goal>test</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
    <dependencies>
        <dependency>
            <groupId>com.fasterxml.jackson.module</groupId>
            <artifactId>jackson-module-scala_2.11</artifactId>
            <version>2.6.7.1</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-common</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_2.11</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
            <exclusions>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-databind</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-module-scala_2.11</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_2.11</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
            <exclusions>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-databind</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-module-scala_2.11</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming_2.11</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
            <exclusions>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-databind</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-module-scala_2.11</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-mllib_2.11</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
            <exclusions>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-databind</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>jackson-module-scala_2.11</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>org.scalatest</groupId>
            <artifactId>scalatest_${scala.version.major}</artifactId>
            <version>3.0.3</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scala.version.major}</artifactId>
            <version>${spark.version}</version>
            <type>test-jar</type>
            <scope>test</scope>
        </dependency>
    </dependencies>
</project>
