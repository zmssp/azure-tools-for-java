Feature: Cosmos Serverless Spark Batch Job Testing

  Scenario: submit spark job test
    Given setup a mock cosmos serverless service for 'PUT' detail request '/activityTypes/spark/batchJobs/46c07889-3590-48f8-b2bc-7f52622b5a0b?api-version=2018-02-01-preview' with body '{"name":"ServerlessSession_46c07889-3590-48f8-b2bc-7f52622b5a0b","priority":1000,"properties":{"className":"sample.JavaSparkPi","file":"adl://test.dogfood.net/rufan/serverless/artifact/serverless_artifact.jar","sparkEventsDirectoryPath":"adl://test.dogfood.net/spark-events","name":"Session_46c07889-3590-48f8-b2bc-7f52622b5a0b","driverMemory":"12G","driverCores":4,"executorCores":4,"numExecutors":2,"executorMemory":"12G"}}' to return '{"properties":{"responsePayload":{"id":0,"appInfo":{"driverLogUrl":null,"sparkUiUrl":null},"log":[],"state":"started"},"sparkMasterUI":"https://46c07889-3590-48f8-b2bc-7f52622b5a0b.azuredatalakeanalytics.net"},"id":"46c07889-3590-48f8-b2bc-7f52622b5a0b","priority":1000,"name":"Session_46c07889-3590-48f8-b2bc-7f52622b5a0b","activityType":"spark","submitter":"rufan","analyticsUnits":9,"submitTime":"2018-11-12T23:57:38.327Z","startTime":"2018-11-12T23:57:38.827Z","endTime":"2018-11-13T00:03:20.183Z","state":"Ended"}' with status code 200
    And setup a mock cosmos serverless service for 'GET' request '/activityTypes/spark/batchJobs/46c07889-3590-48f8-b2bc-7f52622b5a0b?api-version=2018-02-01-preview' to return '{"properties":{"responsePayload":{"id":10,"appInfo":{"driverLogUrl":null,"sparkUiUrl":null},"log":[],"state":"started"},"sparkMasterUI":"https://46c07889-3590-48f8-b2bc-7f52622b5a0b.azuredatalakeanalytics.net"},"id":"46c07889-3590-48f8-b2bc-7f52622b5a0b","priority":1000,"name":"Session_46c07889-3590-48f8-b2bc-7f52622b5a0b","activityType":"spark","submitter":"rufan","analyticsUnits":9,"submitTime":"2018-11-12T23:57:38.327Z","startTime":"2018-11-12T23:57:38.827Z","endTime":"2018-11-13T00:03:20.183Z","state":"Ended"}' with status code 200
    And submit a cosmos serverless spark batch job
    Then verify 'PUT' request for '/activityTypes/spark/batchJobs/46c07889-3590-48f8-b2bc-7f52622b5a0b?api-version=2018-02-01-preview'

  Scenario: get submission log
    Given setup a mock cosmos serverless service for 'GET' request '/activityTypes/spark/batchJobs/46c07889-3590-48f8-b2bc-7f52622b5a0b?api-version=2018-02-01-preview' to return '{"properties":{"sparkMasterUI":"https://46c07889-3590-48f8-b2bc-7f52622b5a0b.sparkmasterui.pools.japaneast.konaaccountdogfood.net","livyServerAPI":"http://127.0.0.1:$port","responsePayload":{"id":0,"state":"success"}},"id":"46c07889-3590-48f8-b2bc-7f52622b5a0b","name":"myserverless_0114_1","activityType":"spark","entityType":"batchjobs","submitter":"admin@aad264.ccsctp.net","analyticsUnits":13,"submitTime":"2019-01-14T06:15:07.64Z","startTime":"2019-01-14T06:15:09.053Z","state":"Scheduled","schedulerState":"Ended","result":"None","tags":{},"priority":1000}' with status code 200
    And setup a mock cosmos serverless service for 'GET' request '/batches/0/log?api-version=2018-02-01-preview&from=0&size=128' to return '{"id":0,"from":0,"total":6,"log":["stdout: ","log4j: reset attribute= \"false\".","log4j: Category org.apache.hadoop.hive.ql.exec.FunctionRegistry set to ERROR","log4j: Handling log4j.additivity.org.apache.hadoop.hive.ql.exec.FunctionRegistry=[null]","log4j: Finished configuring.","\nstderr: "]}' with status code 200
    And setup a mock cosmos serverless service for 'GET' request '/batches/0/log?api-version=2018-02-01-preview&from=6&size=128' to return '{"id":0,"from":6,"total":0,"log":[]}' with status code 200
    Then the return log line should be 'Job scheduler state: Ended. Job running state: success.'